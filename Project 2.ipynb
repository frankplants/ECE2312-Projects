{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install packages needed for imports below\n",
    "# ! pip3 install wavio \n",
    "# ! pip3 install librosa\n",
    "# ! pip3 install sounddevice\n",
    "# had to install an earlier version of matplotlib in order to get the librosa waveshow function to work\n",
    "# ! pip3 install matplotlib==3.7.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary modules\n",
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.fft import fft, fftfreq\n",
    "from scipy.fft import rfft, rfftfreq\n",
    "from scipy.io.wavfile import write\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "import numpy as np\n",
    "from scipy.signal import butter,filtfilt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Sampling Rate in Hz\n",
    "sr = 44100\n",
    "\n",
    "# Duration of sound files in seconds\n",
    "duration = 5\n",
    "\n",
    "# spectrogram generation function from project 1, used for all questions\n",
    "def generate_spectrogram(array, sr_in, plot_title, max_freq):\n",
    "    freq = librosa.amplitude_to_db(np.abs(librosa.stft(array)), ref=np.max)\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.ylim(0, max_freq) # limit frequencies plotted to between 0 and 8000 Hz\n",
    "    plt.title(plot_title) # insert plot title based on function input\n",
    "    img = librosa.display.specshow(freq, x_axis='time', y_axis='linear',ax=ax, sr=sr_in)\n",
    "    plt.xlabel(\"Time (seconds)\")\n",
    "    plt.ylabel(\"Frequency (Hertz)\")\n",
    "    fig.colorbar(img, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sine Tone Generation\n",
    "\n",
    "# generate time axis using sample rate and duration from project 1\n",
    "x = np.linspace(0, duration, sr*duration, endpoint=False)\n",
    "\n",
    "# apply input frequency of 5kHz to each time sample\n",
    "frequencies = x*5000\n",
    "\n",
    "# pass frequencies through sine function\n",
    "tone1 = np.sin((2*np.pi)*frequencies)\n",
    "\n",
    "# write sine wave to a wav file\n",
    "write(\"team[]-sinetone.wav\", sr, tone1)\n",
    "\n",
    "# generate spectrogram of 5kHz sine wave\n",
    "generate_spectrogram(tone1, sr, \"5kHz Sine Wave\", 8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chirp Signal Generation\n",
    "\n",
    "# determine frequency increment per time sample\n",
    "freq_step = (8000/(sr*duration))/2\n",
    "\n",
    "# generate time samples\n",
    "x = np.linspace(0, duration, sr*duration, endpoint=False)\n",
    "\n",
    "frequencies = x\n",
    "freq = 0   \n",
    "   \n",
    "# iterate through each time array element and multiply by frequency\n",
    "for i in range(len(frequencies)):\n",
    "    frequencies[i] = x[i]*freq\n",
    "    # increment frequency from 0Hz to 8000Hz\n",
    "    freq = freq+freq_step\n",
    "\n",
    "tone1 = np.sin((2*np.pi)*frequencies)\n",
    "\n",
    "write(\"team[]-chirp.wav\", sr, tone1)\n",
    "generate_spectrogram(tone1, sr, \"0Hz to 8kHz Chirp Signal\", 8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some Fun with Sine Tone \n",
    "\n",
    "# Array of frequencies for each of the five notes\n",
    "note_freq = [466.16, 523.25, 415.3, 207.65, 311.13]\n",
    "# Array of durations in seconds for each note\n",
    "seconds = np.array([0.4, 0.586, 0.857, 0.586, 1.571])\n",
    "# Convert durations in seconds to number of time samples\n",
    "samples = seconds * (sr*duration/5)\n",
    "\n",
    "# generate time samples\n",
    "x = np.linspace(0, duration, sr*duration, endpoint=False)\n",
    "frequencies = x  \n",
    "    \n",
    "# variables used to determine when to switch to next note\n",
    "lower_limit = 0\n",
    "upper_limit = samples[0]\n",
    "current_note = 0\n",
    "\n",
    "# iterate through all time samples (5sec total)\n",
    "for i in range(len(frequencies)):\n",
    "    # if within the duration of a note, multiply by the corresponding frequency\n",
    "    if lower_limit <= i < upper_limit:\n",
    "        frequencies[i] = x[i]*note_freq[current_note]\n",
    "    else:\n",
    "        # increment to the next note\n",
    "        current_note = current_note + 1\n",
    "        # if all notes have been played, multiply the current time sample by zero and \n",
    "        # continue iterating through the remaining time samples\n",
    "        if current_note > len(seconds)-1:\n",
    "            frequencies[i] = x[i]*0\n",
    "            continue\n",
    "        else:\n",
    "            # set lower limit of the next note to upper limit of the last note\n",
    "            lower_limit = upper_limit\n",
    "            # add duration of the next note to the current upper limit \n",
    "            upper_limit = upper_limit + samples[current_note]\n",
    "                \n",
    "tone1 = np.sin((2*np.pi)*frequencies)\n",
    "\n",
    "write(\"team[]-cetk.wav\", sr, tone1)\n",
    "generate_spectrogram(tone1, sr, \"Close Encounters Five Tones\", 700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining Sound Files\n",
    "\n",
    "# load speech wav file from project 1\n",
    "wav_speech, sr1 = librosa.load(\"quick_brown_fox.wav\")\n",
    "\n",
    "# load 5kHz sine wav file\n",
    "wav_sine, sr2 = librosa.load(\"team[]-sinetone.wav\")\n",
    "\n",
    "# add the speech and sine arrays together\n",
    "combined_sound = wav_speech + wav_sine\n",
    "\n",
    "write(\"team[]-speechsine.wav\", sr1, combined_sound)\n",
    "generate_spectrogram(combined_sound, sr1, \"Speech Signal with 5 kHz Sine Wave\", 8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Speech and Audio Filtering\n",
    "\n",
    "# load combined sine and speech wav file\n",
    "speech_sine, sr1 = librosa.load(\"team[]-speechsine.wav\")\n",
    "\n",
    "# set low pass filter cutoff frequency to 4000Hz\n",
    "cutoff = 4000     \n",
    "# calculate nyquist frequency using sampling rate\n",
    "nyq = 0.5 * sr  \n",
    "# set filter polynomial order to 5 to completely remove 5kHz sine wave\n",
    "order = 5      \n",
    "\n",
    "# normalize cutoff frequency using nyquist frequency\n",
    "normal_cutoff = cutoff / nyq \n",
    "\n",
    "# create a Butterworth lowpass filter using Scipy Library\n",
    "b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "\n",
    "# filter the combined wav file using the Butterworth filter\n",
    "filtered_speech_sine = filtfilt(b, a, speech_sine)\n",
    "\n",
    "write(\"team[]-filteredspeechsine.wav\", sr1, filtered_speech_sine)\n",
    "generate_spectrogram(filtered_speech_sine, sr1, \"Filtered Speech Signal\", 8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stereo Fun\n",
    "\n",
    "# load speech wav file from project 1\n",
    "wav_speech, sr1 = librosa.load(\"quick_brown_fox.wav\")\n",
    "\n",
    "# load combined sine and speech file\n",
    "speech_sine, sr2 = librosa.load(\"team[]-speechsine.wav\")\n",
    "\n",
    "# combine wav files with speech only on the left channel and speech + sine on the right channel\n",
    "stereo_fun = np.hstack((wav_speech.reshape(-1, 1), speech_sine.reshape(-1, 1)))\n",
    "\n",
    "write(\"team[]-stereospeechsine.wav\", sr1, stereo_fun)\n",
    "\n",
    "generate_spectrogram(wav_speech, sr1, \"Stereo Left Channel\", 8000)\n",
    "generate_spectrogram(speech_sine, sr2, \"Stereo Right Channel\", 8000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
